{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from constants import *\n",
    "from collections import Counter\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[logging.FileHandler(\"/home/chance/GitHub/gradient_boosted_dns/log/debug.log\", mode=\"w\")],\n",
    ")\n",
    "\n",
    "def ratio_calculator(row: pd.Series, char_type: str) -> float:\n",
    "    # Copyright (C) 2020 Claudio Marques - All Rights Reserved\n",
    "    # Modified 2023 Chance Tudor\n",
    "    \"\"\"Calculates the percentage of specific character types that make up a domain name.\"\"\"\n",
    "    domain = row[\"domain\"]\n",
    "    try:\n",
    "        return len([char for char in domain if char in char_type]) / len(domain)\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Error in ratio_calculator(): {e}\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def sequence_calculator(row: pd.Series, char_type: str) -> int:\n",
    "    # Copyright (C) 2020 Claudio Marques - All Rights Reserved\n",
    "    # Modified 2023 Chance Tudor\n",
    "    \"\"\"Calculates the maximum number of consecutive character sequences.\"\"\"\n",
    "    domain = row[\"domain\"]\n",
    "    try:\n",
    "        return max(\n",
    "            map(len, \"\".join(i if i in char_type else \" \" for i in domain).split())\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Error in sequence_calculator(): {e}\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def strange_char_count(row: pd.Series) -> int:\n",
    "    # Copyright (C) 2020 Claudio Marques - All Rights Reserved\n",
    "    # Modified 2023 Chance Tudor\n",
    "    \"\"\"Returns the number of strange characters, defined as number of characters different from [a-zA-Z]\"\"\"\n",
    "    domain = row[\"domain\"]\n",
    "    try:\n",
    "        domain = re.sub(r\"[a-zA-Z\\.]+\", \"\", domain)\n",
    "        if len(domain) > 0:\n",
    "            digits = sum(char.isdigit() for char in domain)\n",
    "            digits = 0 if digits <= 2 else digits - 2\n",
    "            domain = re.sub(r\"[0-9]+\", \"\", domain)\n",
    "            return len(domain) + digits\n",
    "        return 0\n",
    "    except Exception as e:\n",
    "        logging.exception(f\"Error in strange_char_count(): {e}\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def entropy(row: pd.Series) -> float:\n",
    "    domain = row[\"domain\"]\n",
    "    try:\n",
    "        p, lens = Counter(domain), np.float(len(domain))\n",
    "        print(p)\n",
    "        print(lens)\n",
    "        print((-np.sum(count / lens * np.log2(count / lens) for count in p.values())))\n",
    "        return -np.sum(count / lens * np.log2(count / lens) for count in p.values())\n",
    "    except Exception as e:\n",
    "        print(f\"Error in entropyCalc(): {e}\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def create_dataset(in_file: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(in_file)\n",
    "    df[\"domain\"] = df[\"domain\"].astype(str)\n",
    "    # df[\"domain_length\"] = df[\"domain\"].apply(lambda row: len(row)).astype(int)\n",
    "    # df[\"strange_char_count\"] = df.apply(strange_char_count, axis=1).astype(int)\n",
    "    # df[\"numeric_sequence\"] = df.apply(\n",
    "    #     lambda row: sequence_calculator(row, CharDef.NUMERIC.value), axis=1\n",
    "    # ).astype(int)\n",
    "    # df[\"numeric_ratio\"] = df.apply(\n",
    "    #     lambda row: ratio_calculator(row, CharDef.NUMERIC.value), axis=1\n",
    "    # ).astype(float)\n",
    "    # df[\"consonant_sequence\"] = df.apply(  # new\n",
    "    #     lambda row: sequence_calculator(row, CharDef.CONSONANT.value), axis=1\n",
    "    # ).astype(int)\n",
    "    df[\"entropy\"] = df.apply(lambda row: entropy(row), axis=1).astype(float)\n",
    "    # df[\"consonant_ratio\"] = df.apply(\n",
    "    #     lambda row: ratio_calculator(row, CharDef.CONSONANT.value), axis=1\n",
    "    # ).astype(float)\n",
    "    # df[\"vowel_sequence\"] = df.apply(  # new\n",
    "    #     lambda row: sequence_calculator(row, CharDef.VOWEL.value), axis=1\n",
    "    # ).astype(int)\n",
    "    # df[\"vowel_ratio\"] = df.apply(\n",
    "    #     lambda row: ratio_calculator(row, CharDef.VOWEL.value), axis=1\n",
    "    # ).astype(float)\n",
    "    # df[\"special_char_sequence\"] = df.apply(  # new\n",
    "    #     lambda row: sequence_calculator(row, CharDef.SPECIALCHAR.value), axis=1\n",
    "    # ).astype(int)\n",
    "    # df[\"special_char_ratio\"] = df.apply(  # new\n",
    "    #     lambda row: ratio_calculator(row, CharDef.SPECIALCHAR.value), axis=1\n",
    "    # ).astype(int)\n",
    "    # df[\"class\"] = (\n",
    "    #     int(1) if \"sus\" in in_file else int(0)\n",
    "    # )  # 1 means malicious, 0 means benign\n",
    "\n",
    "    return df.convert_dtypes()\n",
    "\n",
    "\n",
    "def create_and_write():\n",
    "    datasets = [\n",
    "        FileDef.SANS_HIGH.value,\n",
    "        FileDef.SANS_MED.value,\n",
    "        FileDef.SANS_LOW.value,\n",
    "        FileDef.OISD.value,\n",
    "        FileDef.CERTPL.value,\n",
    "        FileDef.AIRVPN.value,\n",
    "        FileDef.BENIGN.value,\n",
    "    ]\n",
    "    for i, dset in enumerate(datasets):\n",
    "        df = create_dataset(dset).drop_duplicates(subset=\"domain\")\n",
    "        if i == 0:  # if first dataset\n",
    "            df.to_csv(\n",
    "                FileDef.ALL.value, index=False, mode=\"w\", header=True\n",
    "            )  # write the header\n",
    "        else:\n",
    "            df.to_csv(\n",
    "                FileDef.ALL.value, index=False, mode=\"a\", header=False\n",
    "            )  # else, don't write the header\n",
    "\n",
    "\n",
    "def clean(in_file: str, out_file: str):\n",
    "    df = pd.read_csv(in_file).drop_duplicates(subset=\"domain\")\n",
    "    # df[\"id\"] = np.arange(len(df), dtype=np.int64)  # add id\n",
    "    df.to_csv(out_file, index=False, mode=\"w\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_and_write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean(FileDef.ALL.value, FileDef.ALL.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(FileDef.ALL.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
