{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from constants import *\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def split_data(data):\n",
    "    print(f\"SIZE OF DATA = {data.shape[0]}\")\n",
    "    positive_data = data[data[\"class\"] == 1]\n",
    "    negative_data = data[data[\"class\"] == 0]\n",
    "\n",
    "    # Split positive data\n",
    "    pos_test_val, pos_train = train_test_split(\n",
    "        positive_data, test_size=0.5, random_state=42, stratify=positive_data[\"class\"]\n",
    "    )\n",
    "    print(f\"POS TRAIN ROWS = {pos_train.shape[0]}\")\n",
    "    print(f\"POS TEST_VAL ROWS = {pos_test_val.shape[0]}\")\n",
    "\n",
    "    pos_test, pos_val = train_test_split(\n",
    "        pos_test_val, test_size=0.25, random_state=42, stratify=pos_test_val[\"class\"]\n",
    "    )\n",
    "    print(f\"POS TEST ROWS = {pos_test.shape[0]}\")\n",
    "    print(f\"POS VAL ROWS = {pos_val.shape[0]}\")\n",
    "\n",
    "    # Split negative data\n",
    "    neg_test_val, neg_train = train_test_split(\n",
    "        negative_data, test_size=0.5, random_state=42, stratify=negative_data[\"class\"]\n",
    "    )\n",
    "    print(f\"NEG TEST ROWS = {neg_train.shape[0]}\")\n",
    "    print(f\"NEG TEST_VAL ROWS = {neg_test_val.shape[0]}\")\n",
    "\n",
    "    neg_test, neg_val = train_test_split(\n",
    "        neg_test_val, test_size=0.25, random_state=42, stratify=neg_test_val[\"class\"]\n",
    "    )\n",
    "    print(f\"NEG TEST ROWS = {neg_test.shape[0]}\")\n",
    "    print(f\"NEG VALIDATION ROWS = {neg_val.shape[0]}\")\n",
    "\n",
    "    # Training dataset\n",
    "    train = pd.concat([pos_train, neg_train])\n",
    "    # Validation dataset\n",
    "    val = pd.concat([pos_val, neg_val])\n",
    "    # Test dataset\n",
    "    test = pd.concat([pos_test, neg_test])\n",
    "\n",
    "    # Shuffle to ensure randomness\n",
    "    train = train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    val = val.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    test = test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    assert train[\"domain\"].nunique() == len(train)\n",
    "    assert val[\"domain\"].nunique() == len(val)\n",
    "    assert test[\"domain\"].nunique() == len(test)\n",
    "    assert data.shape[0] == len(train) + len(val) + len(test)\n",
    "\n",
    "    return train, val, test\n",
    "\n",
    "\n",
    "def save_data(train, val, test, path=\"data/\"):\n",
    "    train.to_csv(path + \"train.csv\", index=False)\n",
    "    val.to_csv(path + \"val.csv\", index=False)\n",
    "    test.to_csv(path + \"test.csv\", index=False)\n",
    "\n",
    "\n",
    "def split_and_save_data(file_path, data_dir=\"data/\"):\n",
    "    data = read_data(file_path)\n",
    "    train, val, test = split_data(data)\n",
    "    save_data(train, val, test, path=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIZE OF DATA = 2136074\n",
      "POS TRAIN ROWS = 573445\n",
      "POS TEST_VAL ROWS = 573444\n",
      "POS TEST ROWS = 430083\n",
      "POS VAL ROWS = 143361\n",
      "NEG TEST ROWS = 494593\n",
      "NEG TEST_VAL ROWS = 494592\n",
      "NEG TEST ROWS = 370944\n",
      "NEG VALIDATION ROWS = 123648\n"
     ]
    }
   ],
   "source": [
    "split_and_save_data(FileDef.ALL.value, data_dir=\"/home/chance/GitHub/gradient_boosted_dns/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
