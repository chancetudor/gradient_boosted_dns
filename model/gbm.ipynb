{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from constants import FileDef\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_path: str, val_path: str, test_path: str) -> pd.DataFrame:\n",
    "    train = pd.read_csv(train_path)\n",
    "    val = pd.read_csv(val_path)\n",
    "    test = pd.read_csv(test_path)\n",
    "\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(\n",
    "    train: pd.DataFrame, val: pd.DataFrame, test: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    drop_cols = [\"domain\", \"class\"]\n",
    "    normalize_cols = [\"domain_length\", \"strange_char_count\", \"numeric_sequence\", \"special_char_sequence\"]\n",
    "\n",
    "    X_train = train.drop(columns=drop_cols)\n",
    "    X_train[normalize_cols] = X_train[normalize_cols].apply(zscore)\n",
    "    y_train = train[\"class\"].convert_dtypes()\n",
    "\n",
    "    X_val = val.drop(columns=drop_cols)\n",
    "    X_val[normalize_cols] = X_val[normalize_cols].apply(zscore)\n",
    "    y_val = val[\"class\"].convert_dtypes()\n",
    "\n",
    "    X_test = test.drop(columns=drop_cols)\n",
    "    X_test[normalize_cols] = X_test[normalize_cols].apply(zscore)\n",
    "    y_test = test[\"class\"].convert_dtypes()\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    X_train: pd.DataFrame,\n",
    "    y_train: pd.DataFrame,\n",
    "    eval_set: list,\n",
    "    params: dict,\n",
    ") -> XGBClassifier:\n",
    "    print(\"*** TRAINING ***\")\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        eval_set=eval_set, \n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(\n",
    "    model: XGBClassifier,\n",
    "    # X_train: pd.DataFrame,\n",
    "    # y_train: pd.DataFrame,\n",
    "    X_val: pd.DataFrame,\n",
    "    y_val: pd.DataFrame,\n",
    ") -> dict:\n",
    "    print(\"*** TUNING ***\")\n",
    "    # define the original parameter grid, used with RandomizedSearchCV\n",
    "    # param_grid = {\n",
    "    #     \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    #     \"max_depth\": [3, 5, 7],\n",
    "    #     \"min_child_weight\": [1, 3, 5],\n",
    "    #     \"gamma\": [0.0, 0.1, 0.2],\n",
    "    #     \"subsample\": [0.6, 0.8, 1.0],\n",
    "    #     \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    #     \"reg_alpha\": [0, 0.001, 0.01, 0.1, 1],\n",
    "    #     \"reg_lambda\": [0, 0.001, 0.01, 0.1, 1],\n",
    "    #     \"n_estimators\": [100, 300, 500],\n",
    "    # }\n",
    "\n",
    "    # this is the second round of tuning\n",
    "    param_grid = {\n",
    "        \"gamma\": [0.08, 0.1, 0.12],\n",
    "        \"subsample\": [0.9, 1.0],\n",
    "        \"reg_lambda\": [0.8, 1.0, 1.2],\n",
    "        \"reg_alpha\": [0.05, 0.1, 0.15],\n",
    "        \"min_child_weight\": [1, 2],\n",
    "        \"max_depth\": [4, 5, 6],\n",
    "        \"colsample_bytree\": [0.9, 1.0],\n",
    "    }\n",
    "\n",
    "    # define the cross-validation strategy\n",
    "    cv = RepeatedStratifiedKFold(random_state=42)\n",
    "\n",
    "    # perform the grid search\n",
    "    grid_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_grid,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        scoring=\"accuracy\",\n",
    "        verbose=2,\n",
    "    )\n",
    "\n",
    "    # fit the grid search to the data\n",
    "    grid_search.fit(\n",
    "        X_val,\n",
    "        y_val,\n",
    "    )\n",
    "\n",
    "    # get the best hyperparameters\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-score:\", f1)\n",
    "    print(\"Confusion matrix:\\n\", cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = load_data(\n",
    "    FileDef.TRAIN.value, FileDef.VALIDATE.value, FileDef.TEST.value\n",
    ")\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = preprocess_data(train, val, test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TRAINING ***\n",
      "Accuracy: 0.8317559832564945\n",
      "Precision: 0.9162872391112514\n",
      "Recall: 0.7556866930336702\n",
      "F1-score: 0.8282737670492772\n",
      "Confusion matrix:\n",
      " [[341251  29693]\n",
      " [105075 325008]]\n"
     ]
    }
   ],
   "source": [
    "# define our parameters for the model\n",
    "train_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"n_estimators\": 500,\n",
    "    \"booster\": \"gbtree\",\n",
    "    \"grow_policy\": \"lossguide\",\n",
    "    \"n_jobs\": -1,\n",
    "    \"subsample\": 1.0,\n",
    "    \"reg_lambda\": 1.0,\n",
    "    \"reg_alpha\": 0.15,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"max_depth\": 7,\n",
    "    \"learning_rate\": 0.06,\n",
    "    \"gamma\": 0.12,\n",
    "    \"colsample_bytree\": 0.9,\n",
    "    # \"early_stopping_rounds\": 10\n",
    "} # these are the tuned hyperparameters\n",
    "\n",
    "eval_set = [(X_val, y_val), (X_test, y_test)]\n",
    "model = train_model(X_train, y_train, eval_set, train_params)\n",
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'domain_length': 309.6103820800781,\n",
       " 'strange_char_count': 42.95644760131836,\n",
       " 'numeric_sequence': 51.983306884765625,\n",
       " 'consonant_ratio': 55.15205383300781,\n",
       " 'vowel_ratio': 104.23319244384766,\n",
       " 'special_char_sequence': 59.00568771362305}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_booster().get_score(importance_type='gain')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune and retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** TUNING ***\n",
      "Fitting 50 folds for each of 10 candidates, totalling 500 fits\n",
      "[CV] END colsample_bytree=1.0, gamma=0.08, max_depth=5, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, subsample=1.0; total time=  57.4s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.08, max_depth=5, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, subsample=1.0; total time=  59.2s\n",
      "[CV] END colsample_bytree=1.0, gamma=0.08, max_depth=5, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, subsample=1.0; total time= 1.0min\n",
      "[CV] END colsample_bytree=1.0, gamma=0.08, max_depth=5, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, subsample=1.0; total time= 1.0min\n",
      "[CV] END colsample_bytree=1.0, gamma=0.08, max_depth=5, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, subsample=1.0; total time= 1.0min\n",
      "[CV] END colsample_bytree=1.0, gamma=0.08, max_depth=5, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, subsample=1.0; total time= 1.0min\n",
      "[CV] END colsample_bytree=1.0, gamma=0.08, max_depth=5, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, subsample=1.0; total time= 1.0min\n",
      "[CV] END colsample_bytree=1.0, gamma=0.08, max_depth=5, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, subsample=1.0; total time= 1.0min\n",
      "[CV] END colsample_bytree=1.0, gamma=0.08, max_depth=5, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, subsample=1.0; total time= 1.0min\n",
      "[CV] END colsample_bytree=1.0, gamma=0.08, max_depth=5, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, subsample=1.0; total time= 1.1min\n",
      "[CV] END colsample_bytree=1.0, gamma=0.08, max_depth=5, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, subsample=1.0; total time= 1.1min\n",
      "[CV] END colsample_bytree=1.0, gamma=0.08, max_depth=5, min_child_weight=1, reg_alpha=0.05, reg_lambda=1.0, subsample=1.0; total time= 1.2min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tuned_params \u001b[39m=\u001b[39m tune_model(model, X_val, y_val)  \u001b[39m# X_test, y_train,\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(tuned_params)\n",
      "Cell \u001b[0;32mIn[6], line 47\u001b[0m, in \u001b[0;36mtune_model\u001b[0;34m(model, X_val, y_val)\u001b[0m\n\u001b[1;32m     37\u001b[0m grid_search \u001b[39m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     38\u001b[0m     estimator\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     39\u001b[0m     param_distributions\u001b[39m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     43\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     44\u001b[0m )\n\u001b[1;32m     46\u001b[0m \u001b[39m# fit the grid search to the data\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     48\u001b[0m     X_val,\n\u001b[1;32m     49\u001b[0m     y_val,\n\u001b[1;32m     50\u001b[0m )\n\u001b[1;32m     52\u001b[0m \u001b[39m# get the best hyperparameters\u001b[39;00m\n\u001b[1;32m     53\u001b[0m best_params \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    876\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1767\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[1;32m   1769\u001b[0m         ParameterSampler(\n\u001b[1;32m   1770\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_distributions, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter, random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state\n\u001b[1;32m   1771\u001b[0m         )\n\u001b[1;32m   1772\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m         clone(base_estimator),\n\u001b[1;32m    824\u001b[0m         X,\n\u001b[1;32m    825\u001b[0m         y,\n\u001b[1;32m    826\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    827\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    828\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    829\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    830\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    831\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    834\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    835\u001b[0m     )\n\u001b[1;32m    836\u001b[0m )\n\u001b[1;32m    838\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/joblib/parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1061\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1062\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/joblib/parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, \u001b[39m'\u001b[39m\u001b[39msupports_timeout\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 938\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout))\n\u001b[1;32m    939\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output\u001b[39m.\u001b[39mextend(job\u001b[39m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[39mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[39mreturn\u001b[39;00m future\u001b[39m.\u001b[39;49mresult(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m    543\u001b[0m \u001b[39mexcept\u001b[39;00m CfTimeoutError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_condition\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tuned_params = tune_model(model, X_val, y_val)  # X_test, y_train,\n",
    "# print(tuned_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999990637037259\n",
      "Precision: 1.0\n",
      "Recall: 0.9999982561535979\n",
      "F1-score: 0.9999991280760386\n",
      "Confusion matrix:\n",
      " [[494593      0]\n",
      " [     1 573444]]\n"
     ]
    }
   ],
   "source": [
    "# # retrain using better parameters\n",
    "# tuned_model = train_model(X_train, y_train, X_val, y_val, tuned_params)\n",
    "\n",
    "# evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
